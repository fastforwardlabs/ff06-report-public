## Introduction

Our society is increasingly dependent on intelligent machines. Algorithms
govern everything from which e-mails reach our inboxes to whether we are approved
for credit to whom we get the opportunity to date. And their impact on our
experience of the world is growing.

![As algorithmic systems become more prevalent, the need to understand them grows.](figures/1-02.png)

This rise in the use of algorithms coincides with a surge in the capabilities
of _black-box_ techniques, or algorithms whose inner workings cannot easily be
explained. The question of interpretability has been important in applied
machine learning for many years, but as black-box techniques like deep learning
grow in popularity, it's becoming an urgent concern. These techniques offer
breakthrough capabilities in analyzing and even generating rich media and text
data. These systems are so effective in part because they abstract out the need
for manual feature engineering. This allows for automated systems that are able
to do completely new things, but are unable to easily explain _how_ they do
those things.

Interpretability is relevant to anyone who designs systems using machine
learning, from engineers and data scientists to business leaders and executives
who are considering new product opportunities. It allows you to better
understand your machine learning systems and thus generate more useful results.
It helps to explain algorithmic predictions and therefore change real-world
outcomes. It is necessary in regulated industries where you have to prove that
business practices are not dangerous or discriminatory. Further,
interpretability is a key tool in understanding bias and accountability in the
increasingly automated systems we are deploying throughout society.

![With tools that aid interpretability, we can gain insight into black-box systems.](figures/1-01.png)

In this report, we explore two areas of progress in interpretability: systems
designed to be perfectly interpretable, or _white-box_ algorithms, and emerging
research on approaches for inspecting black-box algorithms.
