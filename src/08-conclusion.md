== Conclusion

Interpretability is a powerful and increasingly essential capability. A model
you can interpret and understand is one you can more easily improve. It is also
one you, regulators, and society can more easily trust to be safe and
nondiscriminatory. And an accurate model that is also interpretable can offer
insights that can be used to change real-world outcomes for the better.

There is a central tension, however, between accuracy and interpretability: the
most accurate models are necessarily the hardest to understand. This report was
about two recent breakthroughs that resolve this tension. New white-box
algorithms offer better performance while guaranteeing interpretability.
Meanwhile, model-agnostic interpretability techniques such as LIME allow you to
peer inside black-box models.

Our prototype makes these possibilities concrete. An accurate model that
predicts which customers your business is about to lose is useful. But it's much
more useful if you can also see _why_ they are about to leave. In this way, you
learn about weaknesses in your business, and can perhaps even intervene to
prevent the losses. The techniques demonstrated in this prototype point the way 
toward building tools that can inspect any black-box model to understand how it functions.

The future is algorithmic. White-box models and techniques for making black-box
models interpretable offer a safer, more productive, and ultimately more
collaborative relationship between humans and intelligent machines. We are just
at the beginning of the conversation about interpretability and will see the
impact over the coming years.
